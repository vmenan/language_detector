{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5cb28cd-996f-44f5-976b-b14e197979d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all essential libs\n",
    "import pdftotext\n",
    "import os\n",
    "import fasttext\n",
    "import re\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f80540f0-8234-4844-9206-607117b1e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide the path to the pdfs and model of the language identifier.\n",
    "FOLDER_PATH = \"./data/\"\n",
    "MODEL_PATH = \"./model/lid218e.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3016fbfb-c1a4-48dd-a128-1bb31cd6ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the pdfs in a given folder\n",
    "def get_pdf_names(folder_path):\n",
    "    # Get a list of all files in the specified folder\n",
    "    files_in_folder = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out files that end with '.pdf'\n",
    "    pdf_files = [file for file in files_in_folder if file.lower().endswith('.pdf')]\n",
    "    \n",
    "    return pdf_files\n",
    "\n",
    "def get_tokens(pdf):\n",
    "    #lets iterate page by page and get tokens based on the provide regex.\n",
    "    #remove newline character and replace with space\n",
    "    tokens = []\n",
    "    for page in pdf:\n",
    "        page = page.replace('\\r\\n',\" \")\n",
    "        tokens_temp = re.findall(r\"\\w+|[^\\w\\s]+\", page)\n",
    "        tokens.extend(tokens_temp)\n",
    "    return tokens\n",
    "\n",
    "def calculate_percentages(item_list):\n",
    "    # Count the frequency of each item in the list\n",
    "    item_counts = Counter(item_list)\n",
    "    \n",
    "    # Get the total number of items in the list\n",
    "    total_items = len(item_list)\n",
    "    \n",
    "    # Calculate the percentage of each item and round to 2 decimal places\n",
    "    item_percentages = {item: round((count / total_items) * 100, 2) for item, count in item_counts.items()}\n",
    "    \n",
    "    return item_percentages\n",
    "\n",
    "def get_top_key_by_value(dictionary):\n",
    "    # Sort the dictionary by values in descending order\n",
    "    sorted_dict = sorted(dictionary.items(), key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    # Get the top key with the highest value\n",
    "    top_key = sorted_dict[0][0] if sorted_dict else None  # Handle empty dictionary case\n",
    "    \n",
    "    return top_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddbadfb-b009-4d48-9866-ade66bbcf4c7",
   "metadata": {},
   "source": [
    "## Steps followed\n",
    "We will follow a three step procedure to identify the language of the document.\n",
    "\n",
    " 1. Convert the document (expected as pdf) to text using the `pdftotext` module. This module was fairly straight forward to install before, now it does give some trouble, but I was able install it using the instructions provided in the link [here](https://github.com/jalan/pdftotext).\n",
    " 2. We shall remove all the empty new lines and then split the text in using the following regular expression `\\w+|[^\\w\\s]+` this is one of the simplest pretokenizers used by HuggingFace, which splits in whitespaces.\n",
    " 3. Identify the majority language in the token using the `fasttext` model released by the [NLLB team](https://github.com/facebookresearch/fairseq/tree/nllb?tab=readme-ov-file). You can download the 1GB model using this link [here](https://tinyurl.com/nllblid218e).\n",
    "\n",
    "Finally we report what the majority language was and its percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fdfb94f-de85-4e33-9649-b21edce8a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/7-Mathematical-Foundations-Complete.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#get all the pdfs and their paths\n",
    "pdf_names = get_pdf_names(FOLDER_PATH)\n",
    "#lets create the paths using the names\n",
    "pdf_paths = [ os.path.join(FOLDER_PATH,name) for name in pdf_names]\n",
    "#lets print the paths\n",
    "for path in pdf_paths:\n",
    "    print(path)\n",
    "\n",
    "#lets load up the model\n",
    "model = fasttext.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77359763-6827-4600-af33-cbbaefaac345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------------------------------------------------------#\n",
      "7-Mathematical-Foundations-Complete.pdf has 154 pages.\n",
      "document 7-Mathematical-Foundations-Complete.pdf contains 79.01% eng_Latn\n",
      "#------------------------------------------------------------------------------------#\n"
     ]
    }
   ],
   "source": [
    "#lets now iterate by each pdf and get its contents\n",
    "for path in pdf_paths:\n",
    "    print(\"#------------------------------------------------------------------------------------#\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        pdf = pdftotext.PDF(f)\n",
    "    print(f'{path.split(\"/\")[-1]} has {len(pdf)} pages.')\n",
    "\n",
    "    #lets get tokens from this document\n",
    "    tokens = get_tokens(pdf)\n",
    "\n",
    "    #lets iterate through each token and get\n",
    "    #a language assigned to it.\n",
    "    #since this is independent for each item\n",
    "    #we can parallelize using map function\n",
    "    languages = list(map(lambda x: model.predict(x)[0][0].replace(\"__label__\",\"\"), tokens))\n",
    "    #lets get the percentages\n",
    "    percentages = calculate_percentages(languages)\n",
    "    #lets sort the dictionary and get the language with the highest percentage\n",
    "    top_lang = get_top_key_by_value(percentages)\n",
    "    print(f'document {path.split(\"/\")[-1]} contains {percentages[top_lang]}% {top_lang}')\n",
    "\n",
    "    print(\"#------------------------------------------------------------------------------------#\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e9344-2651-4f86-b369-425e69ef135a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
